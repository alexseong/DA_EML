{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 1: INTRODUCTION\n",
    "\n",
    "- **Classification problem:** supervised learning problem with a categorical response\n",
    "- **Regression problem**: supervised learning problem with a continuous response\n",
    "- **Linear regression:** machine learning model that can be used for regression problems\n",
    "\n",
    "__WHY ARE WE LEARNING LINEAR REGRESSION?__\n",
    "- widely used\n",
    "- runs fast\n",
    "- easy to use (no tuning is required)\n",
    "- highly interpretable\n",
    "- basis for many other methods\n",
    "\n",
    "__LESSON GOALS__\n",
    "\n",
    "- Conceptual understanding of linear regression and how it \"works\"\n",
    "- Familiarity with key terminology\n",
    "- Ability to apply linear regression to a machine learning problem using scikit-learn\n",
    "- Ability to interpret model coefficients\n",
    "- Familiarity with different approaches for feature selection\n",
    "- Understanding of three different evaluation metrics for regression\n",
    "- Understanding of linear regression's strengths and weaknesses\n",
    "\n",
    "__LIBRARIES__\n",
    "\n",
    "- [scikit-learn](http://scikit-learn.org/stable/): \"machine learning in Python\"\n",
    "     - significant functionality for general purpose machine learning\n",
    "\n",
    "__REFERENCES__\n",
    "\n",
    "- [PARAMETRIC vs NON-PARAMETRIC MODELS](https://machinelearningmastery.com/parametric-and-nonparametric-machine-learning-algorithms/)\n",
    "- Linear Regression models are parametric. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SETUP VISUALIZATION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (0.9.0)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from seaborn) (3.0.3)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from seaborn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from seaborn) (1.14.6)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (2.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/alexseong/miniconda3/envs/enterpriseml/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (40.8.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2: READING THE ADVERTISING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a DataFrame\n",
    "ads = pd.read_csv('../data/advertising.csv', index_col=0)\n",
    "ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the observations?\n",
    "- Each observation represents **one market** (200 markets in the dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the features?\n",
    "- **TV:** advertising dollars spent on TV for a single product (in thousands of dollars)\n",
    "- **Radio:** advertising dollars spent on Radio\n",
    "- **Newspaper:** advertising dollars spent on Newspaper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the response?\n",
    "- **Sales:** sales of a single product in a given market (in thousands of widgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions about the data\n",
    "You are asked by the company: On the basis of this data, how should we spend our advertising money in the future?\n",
    "You come up with more specific questions:\n",
    "1. Is there a relationship between ads and sales?\n",
    "2. How strong is that relationship?\n",
    "3. Which ad types contribute to sales?\n",
    "4. What is the effect of each ad type of sales?\n",
    "5. Given ad spending in a particular market, can sales be predicted?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: VISUALIZATION\n",
    "\n",
    "### VISUALIZING THE DATA IN SEABORN\n",
    "* Use a **scatter plot** to visualize the relationship between the features and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot in Seaborn\n",
    "sns.pairplot(ads, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', size=6, aspect=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include a \"regression line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(ads, x_vars=['TV','Radio','Newspaper'], y_vars='Sales', size=6, aspect=0.7, kind='reg')\n",
    "#sns.pairplot(ads, x_vars=['Radio'], y_vars='Newspaper', size=6, aspect=0.7, kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA A SCATTER MATRIX TO VISUALIZE THE RELATIONSHIP BETWEEN ALL NUMERICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix in Seaborn\n",
    "sns.pairplot(ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ads.TV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ads.Newspaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix in seaborn\n",
    "g = sns.pairplot(ads[[\"TV\", \"Radio\", \"Newspaper\", \"Sales\"]], diag_kind=\"hist\", kind=\"reg\")\n",
    "for ax in g.axes.flat:\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE A **CORRELATION MATRIX** TO VISUALIZE THE CORRELATION BETWEEN ALL NUMERCIAL VARIABLES \n",
    "\n",
    "\n",
    "The correlation matrix is a basic, everyday instrument that often can tell the whole story quickly. The correlation is a number between -1 and +1 that measures how close the relationship between two variables is to being linear (i.e., forming a straight line if the two were graphed against each other). Correlation = +1 means variables are perfectly positively correlated (they go up and down in perfect synchronization; e.g., dollars of sales and sales tax); -1 means perfect negative correlation (one goes up and the other goes down; e.g., items sold and inventory); values close to 0 mean either no relation or the relation isn't linear (e.g., annual rainfall and average shoe size). Correlation is independent of scale; measuring one variable in millions and the other in millionths won't affect it. A correlation matrix is simply a grid of the correlations among all the variables, like this:\n",
    "\n",
    "<img src='./images/corr_matrix.jpeg' />\n",
    "\n",
    "This invented example is for a job satisfaction poll. The numbers are invented but typical.\n",
    "\n",
    "Imagine each question asks for a reply on a scale of 1 to 5, with 5 being \"Yes! Yes! Yes!\" and 1 being \"No way! Never!\" and that the questions are:\n",
    "\n",
    "- __Q1__: Are you looking for another job?\n",
    "- __Q2__: Does this job stress you out?\n",
    "- __Q3__: Is your boss difficult to work with?\n",
    "- __Q4__: Do you feel appreciated?\n",
    "- __Q5__: Is your workplace comfortable?\n",
    "\n",
    "Because the correlation of X to Y is always equal to the correlation of Y to X, and a variable is always perfectly correlated (correlation = 1.00) with itself, we can put the correlation matrix into a reduced form, with duplicate values pulled out:\n",
    "\n",
    "<img src='./images/corr_matrix2.jpeg' />\n",
    "\n",
    "Now, what can we learn from this?\n",
    "\n",
    "The sign of the correlation tells us whether the two variables are positively (more X means more Y) or negatively (more X means less Y) related. The absolute value (difference from 0 without regard to sign) tells us how strong the relationship is, and depends on issues about which you'll need to talk to the analyst. Typically for a case like this:\n",
    "\n",
    "<img src='./images/corr_matrix3.jpeg' />\n",
    "\n",
    "If we substitute those interpretations in for the values in the reduced form, now we have:\n",
    "\n",
    "<img src='./images/corr_matrix4.jpeg' />\n",
    "\n",
    "And here's what we can see:\n",
    "\n",
    "__Strong positive correlations__: Q3 with Q2 and Q1. These translate into: \"Jerky bosses are strongly associated with feeling stressed and looking for another job.\" Notice that this is an interpretation; remember, as I wrote about last time, correlation does not require causality. The numbers could just as easily be read to mean that stressed-out, job-hopping employees cause bosses to become jerks. But common sense tends to lean to my interpretation.\n",
    "\n",
    "__Strong negative correlations__: Q4 with Q1 and Q3. There's a close, opposite relation between feeling appreciated (Q4) and planning to leave (Q1) and the jerkiness of the boss (Q3).\n",
    "\n",
    "__Strong negative correlation__: Q5 with Q2. There's a sharp tradeoff: More comfort means less stress (or vice versa, but it seems more likely that a nice environment is relieving worker stress rather than that calm, happy workers are enjoying shabby environments).\n",
    "\n",
    "__Moderate positive__: Q1 and Q2; moderate negative: Q1 and Q5. Stress and comfort have sizable but not overwhelming effects on the decision to look for another job.\n",
    "\n",
    "The results here will not come as a surprise to anyone in business: The unappreciative jerk of a boss is more likely to stress/drive you out than anything else, and a comfy office, cubicle, or workstation helps to reduce stress. Like the correlation matrix itself, it's mostly an expression of common sense.\n",
    "\n",
    "But if you're the manager or analyst reading the correlation matrix, you can look at it to learn something about where your priorities should be:\n",
    "\n",
    "1. Retrain or fire the difficult managers; if there's time and money left after that, maybe...\n",
    "2. Get nicer furniture or enhance the break room.\n",
    "\n",
    "You should try to act on the strong correlations first because they are the most likely to pay off. Getting a new coffeemaker or holding an awards ceremony might be easier and less stressful for you than tackling the difficult manager, but the correlation matrix is clearly telling you that the big rewards in employee retention will come when you bring those rude tyrants into line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation matrix\n",
    "ads.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISPLAY CORRELATION MATRIX IN A SEABORN USING A HEATMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(ads.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 3: SIMPLE LINEAR REGRESSION\n",
    "\n",
    "[The Mathematics of Linear Regression](https://en.m.wikipedia.org/wiki/Linear_least_squares_(mathematics))\n",
    "\n",
    "Simple linear regression is an approach for predicting a **continuous response** using a **single feature**. It takes the following form:\n",
    " $y = \\beta_0 + \\beta_1x$\n",
    " - $y$ is the response\n",
    " - $x$ is the feature\n",
    " - $\\beta_0$ is the intercept\n",
    " - $\\beta_1$ is the coefficient for x\n",
    "\n",
    " $\\beta_0$ and $\\beta_1$ are called the **model coefficients**:\n",
    "\n",
    " - We must \"learn\" the values of these coefficients to create our model.\n",
    " - And once we've learned these coefficients, we can use the model to predict Sales.\n",
    "\n",
    "### Estimating (\"learning\") model coefficients\n",
    " - Coefficients are estimated during the model fitting process using the **least squares criterion**.\n",
    " - We are find the line (mathematically) which minimizes the **sum of squared residuals** (or \"sum of squared errors\").\n",
    "\n",
    "### Estimating Coefficients diagram\n",
    "- The black dots are the **observed values** of x and y.\n",
    "- The blue line is our **least squares line**.\n",
    "- The red lines are the **residuals**, which are the distances between the observed values and the least squares line.\n",
    "\n",
    "![Estimating Coefficients](./images/estimating_coefficients.png)\n",
    "\n",
    "### Slope Intercept diagram\n",
    "![Slope Intercept](./images/slope_intercept.png)\n",
    "\n",
    "### How do the model coefficients relate to the least squares line?\n",
    "- $\\beta_0$ is the **intercept** (the value of $y$ when $x$=0)\n",
    "- $\\beta_1$ is the **slope** (the change in $y$ divided by change in $x$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LET'S ESTIMATE THE MODEL COEFFICIENTS FOR THE ADVERTISING DATA USING SCIKIT-LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV']\n",
    "X = ads[feature_cols]\n",
    "y = ads.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "print (linreg.intercept_)\n",
    "print (linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERPRETING MODEL COEFFICIENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we interpret the TV coefficient ($\\beta_1$)?\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.0475 \"unit\" increase in Sales.\n",
    "- Meaning: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.5 widgets.\n",
    "- This is not a statement of **causation**.\n",
    "\n",
    "### If an increase in TV ad spending was associated with a **decrease** in sales, $\\beta_1$ would be **negative**.\n",
    "\n",
    "### Using the model for prediction\n",
    "\n",
    "Let's say that there was a new market where the TV advertising spend was **$50,000**. What would we predict for the Sales in that market?\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    "$$y = 7.0326 + 0.0475 \\times 50$$\n",
    "\n",
    "### manually calculate the prediction\n",
    "7.0326 + 0.0475*50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT USING SCIKIT-LEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a new observation\n",
    "linreg.predict([[50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Thus, we would predict Sales of **9,409 widgets** in that market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION: Does the scale of the features matter?\n",
    "* Let's say that TV was measured in dollars, rather than thousands of dollars. How would that affect the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV']\n",
    "X = ads[feature_cols]\n",
    "y = ads.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# print the coefficients\n",
    "print (linreg.intercept_)\n",
    "print (linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How do we interpret the TV_dollars coefficient ($\\beta_1$)?\n",
    "- A \"unit\" increase in TV ad spending is **associated with** a 0.0000475 \"unit\" increase in Sales.\n",
    "- Meaning: An additional dollar spent on TV ads is **associated with** an increase in sales of 0.0475 widgets.\n",
    "- Meaning: An additional $1,000 spent on TV ads is **associated with** an increase in sales of 47.5 widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for a new observation\n",
    "linreg.predict([[50000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale of the features is **irrelevant** for linear regression models, since it will only affect the scale of the coefficients, and we simply change our interpretation of the coefficients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 4: A DEEPER UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias and variance\n",
    "#### Linear regression is a low variance/high bias model:\n",
    "- **Low variance:** Under repeated sampling from the underlying population, the line will stay roughly in the same place\n",
    "- **High bias:** The line will rarely fit the data well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well does the model fit the data?\n",
    "\n",
    "#### R-squared:\n",
    "- A common way to evaluate the overall fit of a linear model\n",
    "- Defined as the **proportion of variance explained**, meaning the proportion of variance in the observed data that is explained by the model\n",
    "- Also defined as the reduction in error over the **null model**, which is the model that simply predicts the mean of the observed response\n",
    "- Between 0 and 1, and higher is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HERE'S AN EXAMPLE OF WHAT R-SQUARED \"LOOKS LIKE\":\n",
    "#### Let's calculate the R-squared value for our simple linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the R-squared value for the model\n",
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['Radio']\n",
    "X = ads[feature_cols]\n",
    "y = ads.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['Newspaper']\n",
    "X = ads[feature_cols]\n",
    "y = ads.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'Newspaper', 'Radio']\n",
    "X = ads[feature_cols]\n",
    "y = ads.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The threshold for a **\"good\" R-squared value** is highly dependent on the particular domain.\n",
    "- R-squared is more useful as a tool for **comparing models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 5: MULTIPLE LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression can easily be extended to include multiple features, which is called **multiple linear regression**:\n",
    "#### $y = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$\n",
    "\n",
    "### Each $x$ represents a different feature, and each feature has its own coefficient:\n",
    "#### $y = \\beta_0 + \\beta_1 \\times TV + \\beta_2 \\times Radio + \\beta_3 \\times Newspaper$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads['Ratio'] = (ads['TV'] + ads['Radio'] + ads['Newspaper']) / ads.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\"Ratio\", \"Sales\", data=ads, fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "\n",
    "X = ads[feature_cols]\n",
    "y = ads.Sales\n",
    "\n",
    "# instantiate and fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X, y)\n",
    "\n",
    "# print the coefficients\n",
    "print (linreg.intercept_)\n",
    "print (linreg.coef_)\n",
    "\n",
    "# pair the feature names with the coefficients\n",
    "dict(zip(feature_cols, linreg.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg.predict(X)\n",
    "metrics.r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For a given amount of Radio and Newspaper spending, an increase of $1000 in **TV** spending is associated with an **increase in Sales of 45.8 widgets**.\n",
    "\n",
    "- For a given amount of TV and Newspaper spending, an increase of $1000 in **Radio** spending is associated with an **increase in Sales of 188.5 widgets**.\n",
    "\n",
    "- For a given amount of TV and Radio spending, an increase of $1000 in **Newspaper** spending is associated with an **decrease in Sales of 1.0 widgets**. How could that be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.intercept_ + (linreg.coef_[0] * 1000) + (linreg.coef_[1] * 0) + (linreg.coef_[2] * 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg.predict([[1000, 1000, 2000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 6: FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do I decide **which features to include** in a linear model?\n",
    "\n",
    "* We could try models with different sets of features, and **compare their R-squared values**\n",
    "\n",
    "### However, this approach has **drawbacks**:\n",
    "- Linear models rely upon a lot of **assumptions** (such as the features being independent), and if those assumptions are violated (which they usually are), R-squared is less reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the best model includes **all three features**?\n",
    "- R-squared will always increase as you add more features to the model, even if they are **unrelated** to the response.\n",
    "- As such, using R-squared as a model evaluation metric can lead to **overfitting**.\n",
    "- **Adjusted R-squared** is an alternative that penalizes model complexity (to control for overfitting), but it generally [under-penalizes complexity](http://scott.fortmann-roe.com/docs/MeasuringError.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USING TRAIN/TEST SPLIT (OR CROSS-VALIDATION)\n",
    "- A better approach to feature selection!\n",
    "- They attempt to directly estimate how well your model will **generalize** to out-of-sample data.\n",
    "- They rely on **fewer assumptions** that linear regression.\n",
    "- They can easily be applied to **any model**, not just linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATION METRICS FOR REGRESSION PROBLEMS\n",
    "- Evaluation metrics for classification problems, such as **accuracy**, are not useful for regression problems. We need evaluation metrics designed for comparing **continuous values**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create some example numeric predictions, and calculate three common evaluation metrics for regression problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define true and predicted response values\n",
    "y_true = [100, 50, 30, 20]\n",
    "y_pred = [90, 50, 50, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n",
    "# $$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (metrics.mean_absolute_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean Squared Error** (MSE) is the mean of the squared errors:\n",
    "# $$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (metrics.mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n",
    "# $$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.sqrt(metrics.mean_squared_error(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARING THESE METRICS:\n",
    "- **MAE** is the easiest to understand, because it's the average error.\n",
    "- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n",
    "- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n",
    "\n",
    "#### All of these are **loss functions**, because we want to minimize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 7: USING TRAIN/TEST SPLIT FOR FEATURE SELECTION\n",
    "\n",
    "* Let's use train/test split with RMSE to decide whether Newspaper should be kept in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts X and y and computes testing RMSE\n",
    "def train_test_rmse(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "    y_pred = linreg.predict(X_test)\n",
    "    return np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include Newspaper\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "X = ads[feature_cols]\n",
    "train_test_rmse(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude Newspaper\n",
    "feature_cols = ['TV', 'Radio']\n",
    "X = ads[feature_cols]\n",
    "train_test_rmse(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 8: COMPARING LINEAR REGRESSION WITH OTHER MODELS\n",
    "\n",
    "#### Advantages of linear regression:\n",
    "- Simple to explain\n",
    "- Highly interpretable\n",
    "- Model training and prediction are fast\n",
    "- No tuning is required (excluding regularization)\n",
    "- Features don't need scaling\n",
    "- Can perform well with a small number of observations\n",
    "\n",
    "#### Disadvantages of linear regression:\n",
    "- Presumes a linear relationship between the features and the response\n",
    "- Performance is (generally) not competitive with the best supervised learning methods due to high bias\n",
    "- Sensitive to irrelevant features\n",
    "- Can't automatically learn feature interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES\n",
    "\n",
    "- [Standard Deviation](http://www.mathsisfun.com/data/standard-deviation.html)\n",
    "\n",
    "- [Difference between correlation and covariance](http://stats.stackexchange.com/questions/18082/how-would-you-explain-the-difference-between-correlation-and-covariance)\n",
    "\n",
    "- [What does the correlation matrix tell you? (The Correlation Matrix: Simple Tool, Powerful Insights & Clear Priorities)](http://www.allanalytics.com/author.asp?section_id=1413&doc_id=247352)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
